{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68527f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "import tensorflow as tf\n",
    "pd.set_option('display.max_columns',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364fa1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling links for NBA stats tables\n",
    "link_dict = {\n",
    "    'team_game': 'https://stats.nba.com/stats/leaguedashteamstats?Conference=&DateFrom=&DateTo=&Division=&GameScope=&GameSegment=&LastNGames=0&LeagueID=00&Location=&MeasureType=Base&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PaceAdjust=N&PerMode=PerGame&Period=0&PlayerExperience=&PlayerPosition=&PlusMinus=N&Rank=N&SeasonSegment=&SeasonType=Regular+Season&ShotClockRange=&StarterBench=&TeamID=0&TwoWay=0&VsConference=&VsDivision=',\n",
    "    'player_game': 'https://stats.nba.com/stats/leaguedashplayerstats?College=&Conference=&Country=&DateFrom=&DateTo=&Division=&DraftPick=&DraftYear=&GameScope=&GameSegment=&Height=&LastNGames=0&LeagueID=00&Location=&MeasureType=Base&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PaceAdjust=N&PerMode=PerGame&Period=0&PlayerExperience=&PlayerPosition=&PlusMinus=N&Rank=N&SeasonSegment=&SeasonType=Regular+Season&ShotClockRange=&StarterBench=&TeamID=0&TwoWay=0&VsConference=&VsDivision=&Weight=',\n",
    "    'player_hustle': 'https://stats.nba.com/stats/leaguehustlestatsplayer?College=&Conference=&Country=&DateFrom=&DateTo=&Division=&DraftPick=&DraftYear=&GameScope=&Height=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PaceAdjust=N&PerMode=PerGame&PlayerExperience=&PlayerPosition=&PlusMinus=N&Rank=N&SeasonSegment=&SeasonType=Regular+Season&TeamID=0&VsConference=&VsDivision=&Weight=',\n",
    "    'player_general': 'https://stats.nba.com/stats/playerindex?LeagueID=00'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba661b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers for querying NBA JSON data api\n",
    "headers  = {\n",
    "    'Connection': 'keep-alive',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'x-nba-stats-token': 'true',\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36',\n",
    "    'x-nba-stats-origin': 'stats',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Referer': 'https://stats.nba.com/',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8595c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = ['2017-18','2018-19','2019-20','2020-21','2021-22']\n",
    "params = {'season':'2021-22', 'SeasonType':'Regular+Season'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7297f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_general(season):\n",
    "    params = {'season':season, 'SeasonType':'Regular+Season'}\n",
    "    r = requests.get(url = link_dict['player_general'],headers=headers,params=params).json()\n",
    "    player_general = pd.DataFrame(r['resultSets'][0]['rowSet'],columns=r['resultSets'][0]['headers'])\n",
    "    player_general = player_general[['PLAYER_FIRST_NAME','PLAYER_LAST_NAME','TEAM_ABBREVIATION','PERSON_ID',\n",
    "                                     'POSITION','HEIGHT','WEIGHT','DRAFT_YEAR','FROM_YEAR','TO_YEAR']]\n",
    "    player_general['SEASON'] = season\n",
    "    player_general.rename({'PERSON_ID':'PLAYER_ID'},axis=1,inplace=True)\n",
    "    return player_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e486b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_game(season,min_games=40,min_minutes=15):\n",
    "    drop_cols = ['_RANK','_FANTASY','CFPARA','CFID','TD3','DD2','TEAM_ABBREVIATION','_NAME','NICKNAME']\n",
    "    params = {'season':season, 'SeasonType':'Regular+Season'}\n",
    "    r = requests.get(url = link_dict['player_game'],headers=headers,params=params).json()\n",
    "    player_game = pd.DataFrame(r['resultSets'][0]['rowSet'],columns=r['resultSets'][0]['headers'])\n",
    "    player_game['FTMissed']=player_game['FTA']-player_game['FTM']\n",
    "    player_game['FGMissed']=player_game['FGA']-player_game['FGM']\n",
    "    player_game['FG2M']=player_game['FGM']-player_game['FG3M']\n",
    "    player_game['SEASON'] = season\n",
    "    player_game.drop([col for col in player_game.columns\n",
    "        if re.search(r\"(?=(\"+'|'.join(drop_cols)+r\"))\", col)],axis=1,inplace=True) # drop matching columns\n",
    "    player_game = player_game[(player_game['GP']>=min_games)\\\n",
    "                &(player_game['MIN']>=min_minutes)] # only keep players with enough games and minutes per game\n",
    "    return player_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "effb13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_hustle(season):\n",
    "    params = {'season':season, 'SeasonType':'Regular+Season'}\n",
    "    r = requests.get(url = link_dict['player_hustle'],headers=headers,params=params).json()\n",
    "    player_hustle = pd.DataFrame(r['resultSets'][0]['rowSet'],columns=r['resultSets'][0]['headers'])\n",
    "    player_hustle['SEASON'] = season\n",
    "    return player_hustle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a0d6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_or_concat(seasons, function):\n",
    "    for idx, season in enumerate(seasons):\n",
    "        if idx == 0:\n",
    "            df = function(season)\n",
    "        else:\n",
    "            df = pd.concat([df,function(season)], ignore_index=True, sort=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_general = make_or_concat(seasons, get_player_general)\n",
    "player_game = make_or_concat(seasons, get_player_game)\n",
    "player_hustle = make_or_concat(seasons, get_player_hustle)\n",
    "# all_stats = player_game\\\n",
    "#     .merge(player_general, how='inner', on=['PLAYER_ID'])\\\n",
    "#     .merge(player_hustle.drop('MIN',axis=1),how='inner',on=['PLAYER_ID','SEASON'])\\\n",
    "#     .drop('G',axis=1)\n",
    "# drop_cols = ['_x','NICK','TEAM_ID','_y']\n",
    "# drop_col_matches = [col for col in all_stats.columns\n",
    "#     if re.search(r\"(?=(\"+'|'.join(drop_cols)+r\"))\", col)]\n",
    "# all_stats = all_stats.drop(drop_col_matches,axis=1) # drop matching columns\n",
    "# all_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eaf0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_game\\\n",
    "    .merge(player_general, how='inner', on=['PLAYER_ID','SEASON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce45d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_game.sort_values(by='PLAYER_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_general.sort_values(by='PLAYER_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_hustle.sort_values(by='PLAYER_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1bc668",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats = all_stats.drop(['PLAYER_ID','POSITION'],axis=1)\n",
    "all_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['_x','NICK','TEAM_ID','_y']\n",
    "[col for col in all_stats.columns\n",
    "    if re.search(r\"(?=(\"+'|'.join(drop_cols)+r\"))\", col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77103093",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_general = player_general.merge(\n",
    "        player_hustle.drop('MIN',axis=1),\n",
    "    how='inner',on=['PLAYER_ID','SEASON']).drop('G',axis=1)\n",
    "drop_cols = ['_x','NICK','TEAM_ID','_y']\n",
    "player_general.drop([col for col in player_general.columns\n",
    "    if re.search(r\"(?=(\"+'|'.join(drop_cols)+r\"))\", col)],axis=1,inplace=True) # drop matching columns\n",
    "player_general['POSITION2'] = player_general['POSITION'].str.split('-')\n",
    "player_general = pd.get_dummies(player_general, columns = ['POSITION'])\n",
    "player_general['HEIGHT'] = player_general['HEIGHT'].str.split('-').str[0].astype(int)*12\\\n",
    "    +player_general['HEIGHT'].str.split('-').str[1].astype(int)\n",
    "player_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66537cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "player_general = player_general.merge(pd.DataFrame(mlb.fit_transform(player_general['POSITION2']),columns=mlb.classes_, index=player_general.index),\n",
    "                     how='inner', left_index=True, right_index=True).drop(['POSITION2'],axis=1)\n",
    "player_general['TRUE_SHOOTING_PCT'] = player_general['PTS']/(0.44*player_general['FTA']+player_general['FGA'])\n",
    "player_general['FG2A'] = player_general['FGA'] - player_general['FG3A']\n",
    "player_general['FG2M'] = player_general['FGM'] - player_general['FG3M']\n",
    "player_general['FG2_PCT'] = player_general['FG2M']/player_general['FG2A']\n",
    "player_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea726886",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_index = ['PLUS_MINUS']\n",
    "corr_df = player_general.corr()\n",
    "corr_df[corr_df.index.isin(keep_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9e8cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_plus_minus = player_general.drop(['W_PCT','PLAYER_ID','DRAFT_YEAR','GP','W','L','MIN',\n",
    "                                          'W_PCT','SEASON','PLAYER_NAME','TEAM_ABBREVIATION',\n",
    "                                         'FROM_YEAR','TO_YEAR','HEIGHT','WEIGHT'], axis=1)\n",
    "predict_plus_minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving time for salary with code from here: https://medium.com/swlh/linking-nba-salary-to-performance-sample-player-analysis-with-python-2c568455b306\n",
    "# r = requests.get('https://hoopshype.com/salaries/')\n",
    "# r_html = r.text\n",
    "\n",
    "# soup = BeautifulSoup(r_html, 'html.parser')\n",
    "\n",
    "# salary_table = soup.find('table')\n",
    "# length=len(salary_table.find_all(\"td\"))\n",
    "\n",
    "# player_names=[salary_table.find_all(\"td\")[i].text.strip() for i in range(9,length,8)]\n",
    "\n",
    "# column1=[salary_table.find_all(\"td\")[i].text.strip() for i in range(10,length,8)]\n",
    "# column2=[salary_table.find_all(\"td\")[i].text.strip() for i in range(11,length,8)]\n",
    "# column3=[salary_table.find_all(\"td\")[i].text.strip() for i in range(12,length,8)]\n",
    "# column4=[salary_table.find_all(\"td\")[i].text.strip() for i in range(13,length,8)]\n",
    "# column5=[salary_table.find_all(\"td\")[i].text.strip() for i in range(14,length,8)]\n",
    "# column6=[salary_table.find_all(\"td\")[i].text.strip() for i in range(15,length,8)]\n",
    "# df_dict={'player_names':player_names,\n",
    "#         '2019/20':column1,\n",
    "#         '2020/21':column2,\n",
    "#         '2021/22':column3,\n",
    "#         '2022/23':column4,\n",
    "#         '2023/24':column5,\n",
    "#         '2024/25':column6}\n",
    "        \n",
    "# salary_df = pd.DataFrame(df_dict)\n",
    "# salary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afdf2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_df(df,Y_val,test_size=0.4,random_state=42):\n",
    "    train_features, test_features = train_test_split(df.dropna(),test_size=test_size,random_state=random_state)\n",
    "    train_labels = train_features.pop(Y_val)\n",
    "#     train_labels['Y']=np.where(train_labels.values>0,1,0)\n",
    "#     train_labels['asd']=np.where(train_labels[Y_val]>0,1,0)\n",
    "    test_labels = test_features.pop(Y_val)\n",
    "#     test_labels['asd']=np.where(test_labels[Y_val]>0,1,0)\n",
    "    return np.asarray(train_features.sort_index()).astype(np.float32),\\\n",
    "        np.asarray(train_labels.sort_index()).astype(np.float32),\\\n",
    "        np.asarray(test_features.sort_index()).astype(np.float32),\\\n",
    "        np.asarray(test_labels.sort_index()).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281281a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create the deep neural network model\n",
    "def tf_model(norm):\n",
    "    col_len = train_features.shape[1]\n",
    "    model = tf.keras.Sequential([\n",
    "    norm,\n",
    "    tf.keras.layers.Dense((col_len), activation='relu', input_dim=col_len),\n",
    "#     tf.keras.layers.Dense((col_len)*2, activation='relu'),\n",
    "#     tf.keras.layers.Dense((col_len), activation='relu'),\n",
    "#     tf.keras.layers.Dense(round((col_len)/2), activation='relu'),\n",
    "#     tf.keras.layers.Dense(col_len, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "                 ])\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', #'rmsprop', \n",
    "                 metrics = ['mean_squared_error'] )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = {}\n",
    "y_values = {}\n",
    "x_values = {}\n",
    "normalizer = tf.keras.layers.Normalization()\n",
    "split_nums = [40,600,2432342,4645646,874,9846]\n",
    "for i in split_nums:\n",
    "    # Split the data\n",
    "    train_features, train_labels, test_features, test_labels = train_test_split_df(predict_plus_minus,'PLUS_MINUS',random_state=i)\n",
    "    # Normalize and run TF model\n",
    "#     normalizer = tf.keras.layers.Normalization()\n",
    "    normalizer.adapt(train_features)\n",
    "    tf_m = tf_model(normalizer)\n",
    "    tf_m.fit(train_features, train_labels, epochs=50, verbose=False)\n",
    "    # Run Dummy model\n",
    "    dummy = DummyRegressor(strategy=\"mean\")\n",
    "    dummy.fit(train_features,train_labels)\n",
    "    # Run Ridge model\n",
    "    ridge = Ridge(alpha=1.0)\n",
    "    ridge.fit(train_features,train_labels)\n",
    "    # Run Linear model\n",
    "    lin = LinearRegression()\n",
    "    lin.fit(train_features,train_labels)\n",
    "    # Run Decision Tree model\n",
    "    dtr = tree.DecisionTreeRegressor(max_depth=10)\n",
    "    dtr.fit(train_features,train_labels)\n",
    "    all_models[str(i)+'tf_m'] = tf_m\n",
    "    all_models[str(i)+'dummy'] = dummy\n",
    "    all_models[str(i)+'ridge'] = ridge\n",
    "    all_models[str(i)+'dtr'] = dtr\n",
    "    all_models[str(i)+'lin'] = lin\n",
    "    y_values[i] = test_labels\n",
    "    x_values[i] = test_features\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbcc9cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asd = {}\n",
    "dfasd = pd.DataFrame([[None,None]],columns=['Actual','Pred'])\n",
    "for i in split_nums:\n",
    "    for j in ['tf_m','dummy','ridge','dtr','lin']:\n",
    "        preds = all_models[str(i)+j].predict(x_values[i]).flatten()\n",
    "        r2 = r2_score(y_values[i],preds)\n",
    "        mse = round(1000*mean_squared_error(y_values[i],preds),1)\n",
    "        acc = round(sum(np.sign(preds)==np.sign(y_values[i]))/len(preds),4)\n",
    "        tn, fp, fn, tp = confusion_matrix(np.where(y_values[i]>0,1,0),np.where(preds>0,1,0)).ravel()\n",
    "        posacc = round(tp/(fp+tp),2)\n",
    "        negacc = round(tn/(fn+tn),2)\n",
    "#         tp = \n",
    "#         fn = \n",
    "#         tn = \n",
    "        if j+'r2' in asd:\n",
    "            asd[j+'r2'].append(r2)\n",
    "            asd[j+'mse'].append(mse)\n",
    "            asd[j+'acc'].append(acc)\n",
    "            asd[j+'TN,FP,FN,TP'].append([tn,fp,fn,tp])\n",
    "            asd[j+'posacc'].append(posacc)\n",
    "            asd[j+'negacc'].append(negacc)\n",
    "#             for k in [tn,fp,fn,tp]:\n",
    "#                 asd[j+'TN,FP,FN,TP'].append(k)\n",
    "        else:\n",
    "            asd[j+'r2']=[r2]\n",
    "            asd[j+'mse']=[mse]\n",
    "            asd[j+'acc']=[acc]\n",
    "            asd[j+'TN,FP,FN,TP'] = [[tn,fp,fn,tp]]\n",
    "            asd[j+'posacc'] = [posacc]\n",
    "            asd[j+'negacc'] = [negacc]\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.scatter(y_values[i],preds)\n",
    "        title = str(i)+j+', R2 = '+str(round(r2,4))+', MSE = '+str(mse)+', ACC = '+ str(acc)\n",
    "        plt.suptitle(title)\n",
    "        plt.xlabel('Actual')\n",
    "        plt.ylabel('Predicted')\n",
    "        plt.show()\n",
    "        if j == 'tf':\n",
    "            dfasd=dfasd.append(pd.DataFrame.from_dict({'Actual':y_values[i],'Pred':preds}))\n",
    "#     plt.title(str(i)+'TF, R2 = '+str(r2_score(y_values[i],all_models[str(i)+'tf'].predict(x_values[i]))))\n",
    "#     plt.show()\n",
    "#     plt.scatter(y_values[i],all_models[str(i)+'dummy'].predict(x_values[i]))\n",
    "#     title(str(i)+'dummy, R2 = '+str(r2_score(y_values[i],all_models[str(i)+'dummy'].predict(x_values[i]))))\n",
    "#     plt.show()\n",
    "#     plt.scatter(y_values[i],all_models[str(i)+'ridge'].predict(x_values[i]))\n",
    "#     title(str(i)+'ridge, R2 = '+str(r2_score(y_values[i],all_models[str(i)+'ridge'].predict(x_values[i]))))\n",
    "#     plt.show()\n",
    "#     plt.scatter(y_values[i],all_models[str(i)+'dtr'].predict(x_values[i]))\n",
    "#     title(str(i)+'dtr, R2 = '+str(r2_score(y_values[i],all_models[str(i)+'dtr'].predict(x_values[i]))))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60333907",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization()\n",
    "train_features, train_labels, test_features, test_labels = train_test_split_df(predict_plus_minus,'PLUS_MINUS',random_state=42)\n",
    "normalizer.adapt(train_features)\n",
    "tf_m = tf_model(normalizer)\n",
    "tf_m.fit(train_features, train_labels, epochs=50, verbose=False)\n",
    "preds = tf_m.predict(test_features).flatten()\n",
    "r2 = r2_score(test_labels,preds)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfcc4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "# Make a function for each major processing step\n",
    "    # Make a combined function\n",
    "# Try a deep learning model even though sparse points.\n",
    "# If not enough, get multiple years of data\n",
    "# Try using rank as a feature because it's inherently more normalized\n",
    "# Use LinReg of rank features to gauge importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750409e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_index = ['PLUS_MINUS']\n",
    "player_general_rank = player_general.rank()\n",
    "player_general_rank_norm = player_general_rank/player_general_rank.max()\n",
    "corr_df_rank = player_general_rank.corr()\n",
    "corr_df_rank[corr_df_rank.index.isin(keep_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f58da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create the deep neural network model\n",
    "def tf_model_no_norm():\n",
    "    col_len = train_features.shape[1]\n",
    "    model = tf.keras.Sequential([\n",
    "#     norm,\n",
    "    tf.keras.layers.Dense((col_len), activation='relu', input_dim=col_len),\n",
    "#     tf.keras.layers.Dense((col_len)*2, activation='relu'),\n",
    "#     tf.keras.layers.Dense((col_len), activation='relu'),\n",
    "#     tf.keras.layers.Dense(round((col_len)/2), activation='relu'),\n",
    "#     tf.keras.layers.Dense(col_len, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "                 ])\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', #'rmsprop', \n",
    "                 metrics = ['mean_squared_error'] )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7daa10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_plus_minus_rank_norm = player_general_rank_norm.drop(['W_PCT','PLAYER_ID','DRAFT_YEAR','GP','W','L','MIN',\n",
    "                                          'W_PCT','SEASON','PLAYER_NAME','TEAM_ABBREVIATION',\n",
    "                                         'FROM_YEAR','TO_YEAR','HEIGHT','WEIGHT'], axis=1)\n",
    "all_models = {}\n",
    "y_values = {}\n",
    "x_values = {}\n",
    "normalizer = tf.keras.layers.Normalization()\n",
    "split_nums = [40,600,2432342,4645646,874,9846]\n",
    "for i in split_nums:\n",
    "    # Split the data\n",
    "    train_features, train_labels, test_features, test_labels = train_test_split_df(predict_plus_minus_rank_norm,'PLUS_MINUS',random_state=i)\n",
    "    # Normalize and run TF model\n",
    "#     normalizer = tf.keras.layers.Normalization()\n",
    "    normalizer.adapt(train_features)\n",
    "    tf_m = tf_model_no_norm()\n",
    "    tf_m.fit(train_features, train_labels, epochs=50, verbose=False)\n",
    "    # Run Dummy model\n",
    "    dummy = DummyRegressor(strategy=\"mean\")\n",
    "    dummy.fit(train_features,train_labels)\n",
    "    # Run Ridge model\n",
    "    ridge = Ridge(alpha=1.0)\n",
    "    ridge.fit(train_features,train_labels)\n",
    "    # Run Linear model\n",
    "    lin = LinearRegression()\n",
    "    lin.fit(train_features,train_labels)\n",
    "    # Run Decision Tree model\n",
    "    dtr = tree.DecisionTreeRegressor(max_depth=10)\n",
    "    dtr.fit(train_features,train_labels)\n",
    "    all_models[str(i)+'tf_m'] = tf_m\n",
    "    all_models[str(i)+'dummy'] = dummy\n",
    "    all_models[str(i)+'ridge'] = ridge\n",
    "    all_models[str(i)+'dtr'] = dtr\n",
    "    all_models[str(i)+'lin'] = lin\n",
    "    y_values[i] = test_labels\n",
    "    x_values[i] = test_features\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = {}\n",
    "dfasd = pd.DataFrame([[None,None]],columns=['Actual','Pred'])\n",
    "for i in split_nums:\n",
    "    for j in ['tf_m','dummy','ridge','dtr','lin']:\n",
    "        preds = all_models[str(i)+j].predict(x_values[i]).flatten()\n",
    "        r2 = r2_score(y_values[i],preds)\n",
    "        mse = round(1000*mean_squared_error(y_values[i],preds),1)\n",
    "        if j+'r2' in asd:\n",
    "            asd[j+'r2'].append(r2)\n",
    "            asd[j+'mse'].append(mse)\n",
    "        else:\n",
    "            asd[j+'r2']=[r2]\n",
    "            asd[j+'mse']=[mse]\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.scatter(y_values[i],preds)\n",
    "        title = str(i)+j+', R2 = '+str(round(r2,4))+', MSE = '+str(mse)+', ACC = '+ str(acc)\n",
    "        plt.suptitle(title)\n",
    "        plt.xlabel('Actual')\n",
    "        plt.ylabel('Predicted')\n",
    "        plt.show()\n",
    "        if j == 'tf':\n",
    "            dfasd=dfasd.append(pd.DataFrame.from_dict({'Actual':y_values[i],'Pred':preds}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2433f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_general_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_plus_minus_rank_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_general_per_min = player_general.drop(['W_PCT','PLAYER_ID','DRAFT_YEAR','GP','W','L','MIN',\n",
    "                                          'W_PCT','SEASON','PLAYER_NAME','TEAM_ABBREVIATION',\n",
    "                                         'FROM_YEAR','TO_YEAR','HEIGHT','WEIGHT'],axis=1).div(player_general['MIN'],axis=0)\n",
    "for col in player_general_per_min[[col for col in player_general_per_min.columns if 'PCT' in col or 'POSITION' in col]].columns:\n",
    "    player_general_per_min[col] = player_general[col]\n",
    "player_general_per_min_rank_norm = player_general_per_min.rank()/player_general_per_min.rank().max()\n",
    "player_general_per_min_rank_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b02b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = LinearRegression()\n",
    "importance = []\n",
    "z = 0\n",
    "# lin.fit(player_general_per_min_rank_norm.drop('PLUS_MINUS',axis=1),player_general_per_min_rank_norm['PLUS_MINUS'])\n",
    "for i in player_general_per_min_rank_norm.drop('PLUS_MINUS',axis=1).columns:\n",
    "    lin.fit(player_general_per_min_rank_norm[i].values.reshape(-1,1),player_general_per_min_rank_norm['PLUS_MINUS'])\n",
    "    importance.append(lin.coef_[0])\n",
    "    z+=1\n",
    "plt.figure(figsize=(17,17))\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(player_general_per_min_rank_norm.drop('PLUS_MINUS',axis=1).columns,importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
